{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8dfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7800ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93f563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad99ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹å‚æ•°é‡: 13664256\n",
      "\n",
      "è¾“å…¥å½¢çŠ¶: torch.Size([2, 5])\n",
      "Logits å½¢çŠ¶: torch.Size([2, 5, 50304])\n",
      "\n",
      "Training Loss: 10.8258\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "from nanochat.gpt import GPT, GPTConfig\n",
    "\n",
    "# 1. å®šä¹‰é…ç½® (è¿™é‡Œä½¿ç”¨ä¸€ä¸ªå°æ¨¡å‹ä½œä¸ºæ¼”ç¤º)\n",
    "config = GPTConfig(\n",
    "    vocab_size=50304, # è¯è¡¨å¤§å°\n",
    "    sequence_len=1024,# æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦\n",
    "    n_layer=4,        # Transformer å±‚æ•°\n",
    "    n_head=4,         # æ³¨æ„åŠ›å¤´æ•°\n",
    "    n_kv_head=4,   \n",
    "    n_embd=128        # åµŒå…¥ç»´åº¦\n",
    ")\n",
    "\n",
    "# 2. å®ä¾‹åŒ–æ¨¡å‹\n",
    "model = GPT(config)\n",
    "\n",
    "# 3. åˆå§‹åŒ–æƒé‡ (å…³é”®æ­¥éª¤)\n",
    "# åº”ç”¨ç‰¹å®šçš„æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œå¹¶å°† lm_head å’Œéƒ¨åˆ†æŠ•å½±å±‚ç½®é›¶\n",
    "model.init_weights()\n",
    "\n",
    "print(f\"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# --- åœºæ™¯ A: æ¨ç† (Inference) ---\n",
    "# æ„é€ æ¨¡æ‹Ÿè¾“å…¥: Batch Size=2, Sequence Length=16\n",
    "B, T = 2, 5\n",
    "idx = torch.randint(0, config.vocab_size, (B, T))\n",
    "\n",
    "# å‰å‘ä¼ æ’­ (ä¸ä¼  targets)\n",
    "logits = model(idx)\n",
    "\n",
    "# è¾“å‡ºå½¢çŠ¶: (Batch, Seq_Len, Vocab_Size)\n",
    "print(f\"\\nè¾“å…¥å½¢çŠ¶: {idx.shape}\")\n",
    "print(f\"Logits å½¢çŠ¶: {logits.shape}\") # -> torch.Size([2, 16, 50304])\n",
    "\n",
    "\n",
    "# --- åœºæ™¯ B: è®­ç»ƒ (Training) ---\n",
    "# æ„é€ æ¨¡æ‹Ÿç›®æ ‡ (é€šå¸¸æ˜¯ idx å‘åç§»ä¸€ä½)\n",
    "targets = torch.randint(0, config.vocab_size, (B, T))\n",
    "\n",
    "# å‰å‘ä¼ æ’­ (ä¼ å…¥ targets)\n",
    "loss = model(idx, targets=targets)\n",
    "\n",
    "# è¾“å‡ºæ˜¯ä¸€ä¸ªæ ‡é‡ Loss\n",
    "print(f\"\\nTraining Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747f9430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50225,  8774,  1447,  6861, 46644, 25897, 39148, 21490, 15152, 29623,\n",
       "          1377, 18267, 20870, 17969, 33869, 40159],\n",
       "        [41792, 36984, 17243, 16975, 12120, 11724, 27727, 35220, 29049, 11822,\n",
       "          5502, 20497, 14346, 23403, 19113, 21961]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d906e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token = logits[:, -1, :]\n",
    "print(f\"next_tokenå½¢çŠ¶: {next_token.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866401d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81f881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992e58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0296aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TOKENS: 33\n",
      "['W', 'eng', ' earns', ' $', '12', ' an', ' hour', ' for', ' bab', 'ys', 'itting', '.', ' Y', 'ester', 'day', ',', ' she', ' just', ' did', ' ', '50', ' minutes', ' of', ' bab', 'ys', 'itting', '.', ' How', ' much', ' did', ' she', ' earn', '?']\n",
      "FULL_NUM_TOKENS: 92\n",
      "['<|bos|>', '<|user_start|>', 'W', 'eng', ' earns', ' $', '12', ' an', ' hour', ' for', ' bab', 'ys', 'itting', '.', ' Y', 'ester', 'day', ',', ' she', ' just', ' did', ' ', '50', ' minutes', ' of', ' bab', 'ys', 'itting', '.', ' How', ' much', ' did', ' she', ' earn', '?', '<|user_end|>', '<|assistant_start|>', 'W', 'eng', ' earns', ' ', '12', '/', '60', ' =', ' ', '<|python_start|>', '12', '/', '60', '<|python_end|>', '<|output_start|>', '0', '.', '2', '<|output_end|>', ' per', ' minute', '.', ' Working', ' ', '50', ' minutes', ',', ' she', ' earned', ' ', '0', '.', '2', '*', '50', ' =', ' ', '<|python_start|>', '0', '.', '2', '*', '50', '<|python_end|>', '<|output_start|>', '10', '<|output_end|>', '.\\n', '#', '#', '#', '#', ' ', '10', '<|assistant_end|>']\n",
      "[(\"'<|bos|>'\", 65527, 0), (\"'<|user_start|>'\", 65528, 0), (\"'W'\", 87, 0), (\"'eng'\", 1215, 0), (\"' earns'\", 19585, 0), (\"' $'\", 1794, 0), (\"'12'\", 1029, 0), (\"' an'\", 349, 0), (\"' hour'\", 4076, 0), (\"' for'\", 327, 0), (\"' bab'\", 2353, 0), (\"'ys'\", 638, 0), (\"'itting'\", 12884, 0), (\"'.'\", 46, 0), (\"' Y'\", 704, 0), (\"'ester'\", 6995, 0), (\"'day'\", 1126, 0), (\"','\", 44, 0), (\"' she'\", 953, 0), (\"' just'\", 916, 0), (\"' did'\", 1197, 0), (\"' '\", 32, 0), (\"'50'\", 1288, 0), (\"' minutes'\", 2522, 0), (\"' of'\", 282, 0), (\"' bab'\", 2353, 0), (\"'ys'\", 638, 0), (\"'itting'\", 12884, 0), (\"'.'\", 46, 0), (\"' How'\", 1035, 0), (\"' much'\", 1005, 0), (\"' did'\", 1197, 0), (\"' she'\", 953, 0), (\"' earn'\", 6741, 0), (\"'?'\", 63, 0), (\"'<|user_end|>'\", 65529, 0), (\"'<|assistant_start|>'\", 65530, 0), (\"'W'\", 87, 1), (\"'eng'\", 1215, 1), (\"' earns'\", 19585, 1), (\"' '\", 32, 1), (\"'12'\", 1029, 1), (\"'/'\", 47, 1), (\"'60'\", 1924, 1), (\"' ='\", 3146, 1), (\"' '\", 32, 1), (\"'<|python_start|>'\", 65532, 1), (\"'12'\", 1029, 1), (\"'/'\", 47, 1), (\"'60'\", 1924, 1), (\"'<|python_end|>'\", 65533, 1), (\"'<|output_start|>'\", 65534, 0), (\"'0'\", 48, 0), (\"'.'\", 46, 0), (\"'2'\", 50, 0), (\"'<|output_end|>'\", 65535, 0), (\"' per'\", 541, 1), (\"' minute'\", 7085, 1), (\"'.'\", 46, 1), (\"' Working'\", 13454, 1), (\"' '\", 32, 1), (\"'50'\", 1288, 1), (\"' minutes'\", 2522, 1), (\"','\", 44, 1), (\"' she'\", 953, 1), (\"' earned'\", 10703, 1), (\"' '\", 32, 1), (\"'0'\", 48, 1), (\"'.'\", 46, 1), (\"'2'\", 50, 1), (\"'*'\", 42, 1), (\"'50'\", 1288, 1), (\"' ='\", 3146, 1), (\"' '\", 32, 1), (\"'<|python_start|>'\", 65532, 1), (\"'0'\", 48, 1), (\"'.'\", 46, 1), (\"'2'\", 50, 1), (\"'*'\", 42, 1), (\"'50'\", 1288, 1), (\"'<|python_end|>'\", 65533, 1), (\"'<|output_start|>'\", 65534, 0), (\"'10'\", 734, 0), (\"'<|output_end|>'\", 65535, 0), (\"'.\\\\n'\", 307, 1), (\"'#'\", 35, 1), (\"'#'\", 35, 1), (\"'#'\", 35, 1), (\"'#'\", 35, 1), (\"' '\", 32, 1), (\"'10'\", 734, 1), (\"'<|assistant_end|>'\", 65531, 1)]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from nanochat.tokenizer import get_tokenizer\n",
    "\n",
    "text = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\"\n",
    "\n",
    "tok = get_tokenizer()\n",
    "\n",
    "# 1) ä»…å¯¹è¿™æ®µ user æ–‡æœ¬åš tokenize\n",
    "ids = tok.encode(text)  # list[int]\n",
    "tokens = [tok.id_to_token(i) for i in ids]  # list[str], æ¯ä¸ªå…ƒç´ å°±æ˜¯ä¸€ä¸ª token çš„â€œå­—ç¬¦ä¸²å½¢æ€â€\n",
    "print(\"NUM_TOKENS:\", len(tokens))\n",
    "print(tokens)  # å¦‚æœå¤ªé•¿ä½ ä¹Ÿå¯ä»¥é€è¡Œ print\n",
    "\n",
    "# 2) ä½ çš„æ•´æ¡ GSM8K conversation çš„â€œå®Œæ•´ token æµâ€\n",
    "conv = {\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "    {\"role\": \"assistant\", \"content\": [\n",
    "      {\"type\": \"text\", \"text\": \"Weng earns 12/60 = \"},\n",
    "      {\"type\": \"python\", \"text\": \"12/60\"},\n",
    "      {\"type\": \"python_output\", \"text\": \"0.2\"},\n",
    "      {\"type\": \"text\", \"text\": \" per minute. Working 50 minutes, she earned 0.2*50 = \"},\n",
    "      {\"type\": \"python\", \"text\": \"0.2*50\"},\n",
    "      {\"type\": \"python_output\", \"text\": \"10\"},\n",
    "      {\"type\": \"text\", \"text\": \".\\n#### 10\"},\n",
    "    ]},\n",
    "  ]\n",
    "}\n",
    "\n",
    "full_ids, mask = tok.render_conversation(conv)\n",
    "full_tokens = [tok.id_to_token(i) for i in full_ids]\n",
    "print(\"FULL_NUM_TOKENS:\", len(full_tokens))\n",
    "print(full_tokens)\n",
    "\n",
    "# å¯é€‰ï¼šåŒæ—¶æ‰“å° (token, id, mask) æ–¹ä¾¿æ ¸å¯¹å“ªäº› token æ¥è‡ª user/assistant/tool output\n",
    "triples = [(repr(t), i, m) for t, i, m in zip(full_tokens, full_ids, mask)]\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc78c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37449ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a/Desktop/xinao/reborn1000/build_sell_invest/nanochat/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åŠ è½½ SmolTalk æ•°æ®é›† (split='train')...\n",
      "æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: 460341\n",
      "\n",
      "==================================================\n",
      "æŸ¥çœ‹ç¬¬ 1 ä¸ªæ ·æœ¬ (Index 0):\n",
      "==================================================\n",
      "Message 0 [USER]: A researcher interested in examining students' study time per day collected data...\n",
      "Message 1 [ASSISTANT]: To calculate the mean, we need to add up all the values and divide by the total ...\n",
      "Message 2 [USER]: How would you describe the dispersion of this data set. Which measurement or cal...\n",
      "Message 3 [ASSISTANT]: To describe the dispersion of the data, I would calculate the standard deviation...\n",
      "Message 4 [USER]: Would a median and or a mode be a better representation for the central tendency...\n",
      "Message 5 [ASSISTANT]: In this dataset, the median and mode might be more representative of the central...\n",
      "\n",
      "==================================================\n",
      "æŸ¥çœ‹åˆ‡ç‰‡æ ·æœ¬ (Index 10-12):\n",
      "==================================================\n",
      "Slice Item 0 (Original Index 10): User asks -> Your response should contain at least 3 sentences. Include k...\n",
      "Slice Item 1 (Original Index 11): User asks -> Write a Python function to return a dictionary value by a gi...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from tasks.smoltalk import SmolTalk\n",
    "\n",
    "def main():\n",
    "    print(\"æ­£åœ¨åŠ è½½ SmolTalk æ•°æ®é›† (split='train')...\")\n",
    "    \n",
    "    # 1. åˆå§‹åŒ–ä»»åŠ¡\n",
    "    # split å‚æ•°å¿…é¡»æ˜¯ \"train\" æˆ– \"test\"\n",
    "    # ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ï¼Œdatasets åº“ä¼šè‡ªåŠ¨ä¸‹è½½æ•°æ®å¹¶ç¼“å­˜\n",
    "    task = SmolTalk(split=\"train\")\n",
    "    \n",
    "    print(f\"æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: {len(task)}\")\n",
    "    \n",
    "    # 2. è·å–å¹¶å±•ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"æŸ¥çœ‹ç¬¬ 1 ä¸ªæ ·æœ¬ (Index 0):\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    example = task[0]\n",
    "    messages = example[\"messages\"]\n",
    "    \n",
    "    for i, msg in enumerate(messages):\n",
    "        role = msg[\"role\"].upper()\n",
    "        content = msg[\"content\"]\n",
    "        # ä¸ºäº†å±•ç¤ºæ•´æ´ï¼Œè¿‡é•¿çš„å†…å®¹è¿›è¡Œæˆªæ–­\n",
    "        preview = content[:80].replace('\\n', ' ') + \"...\" if len(content) > 80 else content.replace('\\n', ' ')\n",
    "        print(f\"Message {i} [{role}]: {preview}\")\n",
    "\n",
    "    # 3. å±•ç¤ºåˆ‡ç‰‡åŠŸèƒ½ (ä½¿ç”¨ Task åŸºç±»æä¾›çš„åŠŸèƒ½)\n",
    "    # ä¾‹å¦‚ï¼šåªè·å–ç¬¬ 10 åˆ°ç¬¬ 12 ä¸ªæ ·æœ¬\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"æŸ¥çœ‹åˆ‡ç‰‡æ ·æœ¬ (Index 10-12):\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    sliced_task = SmolTalk(split=\"train\", start=10, stop=12)\n",
    "    \n",
    "    for i in range(len(sliced_task)):\n",
    "        # æ³¨æ„ï¼šsliced_task[0] å®é™…ä¸Šå¯¹åº”åŸå§‹æ•°æ®é›†çš„ task[10]\n",
    "        ex = sliced_task[i]\n",
    "        first_user_msg = ex[\"messages\"][0]\n",
    "        # å¦‚æœç¬¬ä¸€æ¡æ˜¯ systemï¼Œå–ç¬¬äºŒæ¡\n",
    "        if first_user_msg[\"role\"] == \"system\":\n",
    "             first_user_msg = ex[\"messages\"][1]\n",
    "             \n",
    "        print(f\"Slice Item {i} (Original Index {10+i}): User asks -> {first_user_msg['content'][:60]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8013d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: 460341\n",
      "\n",
      "==================================================\n",
      "æŸ¥çœ‹ç¬¬ 1 ä¸ªæ ·æœ¬ (Index 0):\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "task = SmolTalk(split=\"train\")\n",
    "    \n",
    "print(f\"æ•°æ®é›†åŠ è½½å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: {len(task)}\")\n",
    "\n",
    "# 2. è·å–å¹¶å±•ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æŸ¥çœ‹ç¬¬ 1 ä¸ªæ ·æœ¬ (Index 0):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "example = task[0]\n",
    "messages = example[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994b45e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"A researcher interested in examining students' study time per day collected data from a random sample of 20 students. Here are the data: \\n\\n3, 1, 2, 4, 5, 2, 3, 4, 2, 1, 2, 3, 4, 6, 3, 2, 2, 1, 5, 4\\n\\nWhat is the mean of this dataset? How would you describe or interpret the result?\",\n",
       "  'role': 'user'},\n",
       " {'content': 'To calculate the mean, we need to add up all the values and divide by the total number of observations. \\n\\nThe sum of the values is 3 + 1 + 2 + 4 + 5 + 2 + 3 + 4 + 2 + 1 + 2 + 3 + 4 + 6 + 3 + 2 + 2 + 1 + 5 + 4 = 59.\\n\\nThere are 20 observations in the dataset. The mean is calculated by dividing the sum by the number of observations: 59 / 20 = 2.95.\\n\\nThe mean of 2.95 hours per day indicates that, on average, students in this sample spend approximately 3 hours per day studying. This result suggests a relatively moderate amount of daily study time, with most students likely dedicating a few hours to studying each day. However, to better understand the study habits of this sample, further analysis, such as examining the distribution of study times or identifying any outliers, may be necessary.',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'How would you describe the dispersion of this data set. Which measurement or calculation of dispersion would you use to describe and or interpret the dispersion of the data.',\n",
       "  'role': 'user'},\n",
       " {'content': \"To describe the dispersion of the data, I would calculate the standard deviation, as it is a measure of how spread out the individual data points are from the mean value. \\n\\nThe standard deviation is calculated as the square root of the variance. The variance is calculated as the average of the squared differences between each data point and the mean.\\n\\nFirst, calculate the variance:\\n1. Calculate the deviations from the mean: (3-2.95), (1-2.95), (2-2.95), ..., (4-2.95)\\n2. Square these deviations: (0.05)^2, (-1.95)^2, (-0.95)^2, ..., (1.05)^2\\n3. Calculate the average of these squared deviations (variance): Î£(xi - Î¼)^2 / N = 1.3525\\n\\nThen, calculate the standard deviation:\\nStandard deviation (Ïƒ) = âˆšvariance = âˆš1.3525 = 1.16\\n\\nThe standard deviation of 1.16 hours indicates a relatively moderate dispersion in the study times among students. This means that most students' study times do not deviate too far from the mean of 2.95 hours.\\n\\nIn this case, the standard deviation provides a more accurate representation of dispersion than the range (the difference between the maximum and minimum values), as the range can be heavily influenced by extreme values (outliers). The standard deviation, on the other hand, takes into account all the data points and is less affected by outliers.\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Would a median and or a mode be a better representation for the central tendency in this dataset than the mean.',\n",
       "  'role': 'user'},\n",
       " {'content': 'In this dataset, the median and mode might be more representative of the central tendency than the mean due to the presence of a few higher values (5, 6) that may be pulling the mean slightly upwards.\\n\\nTo calculate the median, first, arrange the data in ascending order: 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6. Since there are 20 values (an even number), the median will be the average of the two middle values: (2 + 3) / 2 = 2.5.\\n\\nTo calculate the mode, identify the most frequently occurring value in the dataset. The value \"2\" appears 6 times, making it the mode.\\n\\nConsidering the median (2.5) and mode (2), both are lower than the mean (2.95). This suggests that the mean may be slightly inflated by the higher values in the dataset. The median and mode might provide a more accurate representation of the \"typical\" study time for students in this sample, as they are less affected by extreme values.\\n\\nIn particular, the mode (2) indicates that the most common study time among students is 2 hours per day. This information can be valuable in understanding the study habits of the students. However, it is essential to consider all three measures of central tendency (mean, median, and mode) to get a comprehensive understanding of the data.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5a13c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"You're an AI assistant for text re-writing. Rewrite the input text to make it more professional and formal while retaining its essential content.\",\n",
       "   'role': 'system'},\n",
       "  {'content': \"Hey Alex,\\n\\nSo, I've been thinking a lot about our new project on the etymology of ancient languages, and I have a ton of ideas! I was reading this fascinating article about the Proto-Indo-European roots of some modern words, and it got me thinking about how we could really dive deep into this. Like, we could look at how certain words have evolved over time and see if there are any patterns or commonalities. \\n\\nI know it's a lot to take in, but I think it could be really interesting. Let me know what you think, and maybe we can set up a time to discuss it further. Oh, and don't forget about the conference next month! ğŸ˜Š\\n\\nTalk soon!\\nEleanor\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'Dear Alex,\\n\\nI hope this message finds you well. I have been giving considerable thought to our upcoming project on the etymology of ancient languages and have developed several ideas that I believe could enhance our research. Recently, I came across an insightful article discussing the Proto-Indo-European roots of various modern words. This has inspired me to consider a more in-depth exploration of how certain words have evolved over time, potentially uncovering patterns or commonalities that could be significant to our study.\\n\\nI understand that this is a substantial area of inquiry, but I am confident that it could yield valuable insights. I would appreciate your thoughts on this approach and suggest we schedule a meeting to discuss these ideas in more detail. Additionally, please keep in mind the conference scheduled for next month.\\n\\nI look forward to your response.\\n\\nBest regards,\\nEleanor',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f06ed4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460341"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.num_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03a4bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"A researcher interested in examining students' study time per day collected data from a random sample of 20 students. Here are the data: \\n\\n3, 1, 2, 4, 5, 2, 3, 4, 2, 1, 2, 3, 4, 6, 3, 2, 2, 1, 5, 4\\n\\nWhat is the mean of this dataset? How would you describe or interpret the result?\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'To calculate the mean, we need to add up all the values and divide by the total number of observations. \\n\\nThe sum of the values is 3 + 1 + 2 + 4 + 5 + 2 + 3 + 4 + 2 + 1 + 2 + 3 + 4 + 6 + 3 + 2 + 2 + 1 + 5 + 4 = 59.\\n\\nThere are 20 observations in the dataset. The mean is calculated by dividing the sum by the number of observations: 59 / 20 = 2.95.\\n\\nThe mean of 2.95 hours per day indicates that, on average, students in this sample spend approximately 3 hours per day studying. This result suggests a relatively moderate amount of daily study time, with most students likely dedicating a few hours to studying each day. However, to better understand the study habits of this sample, further analysis, such as examining the distribution of study times or identifying any outliers, may be necessary.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'How would you describe the dispersion of this data set. Which measurement or calculation of dispersion would you use to describe and or interpret the dispersion of the data.',\n",
       "   'role': 'user'},\n",
       "  {'content': \"To describe the dispersion of the data, I would calculate the standard deviation, as it is a measure of how spread out the individual data points are from the mean value. \\n\\nThe standard deviation is calculated as the square root of the variance. The variance is calculated as the average of the squared differences between each data point and the mean.\\n\\nFirst, calculate the variance:\\n1. Calculate the deviations from the mean: (3-2.95), (1-2.95), (2-2.95), ..., (4-2.95)\\n2. Square these deviations: (0.05)^2, (-1.95)^2, (-0.95)^2, ..., (1.05)^2\\n3. Calculate the average of these squared deviations (variance): Î£(xi - Î¼)^2 / N = 1.3525\\n\\nThen, calculate the standard deviation:\\nStandard deviation (Ïƒ) = âˆšvariance = âˆš1.3525 = 1.16\\n\\nThe standard deviation of 1.16 hours indicates a relatively moderate dispersion in the study times among students. This means that most students' study times do not deviate too far from the mean of 2.95 hours.\\n\\nIn this case, the standard deviation provides a more accurate representation of dispersion than the range (the difference between the maximum and minimum values), as the range can be heavily influenced by extreme values (outliers). The standard deviation, on the other hand, takes into account all the data points and is less affected by outliers.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Would a median and or a mode be a better representation for the central tendency in this dataset than the mean.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'In this dataset, the median and mode might be more representative of the central tendency than the mean due to the presence of a few higher values (5, 6) that may be pulling the mean slightly upwards.\\n\\nTo calculate the median, first, arrange the data in ascending order: 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6. Since there are 20 values (an even number), the median will be the average of the two middle values: (2 + 3) / 2 = 2.5.\\n\\nTo calculate the mode, identify the most frequently occurring value in the dataset. The value \"2\" appears 6 times, making it the mode.\\n\\nConsidering the median (2.5) and mode (2), both are lower than the mean (2.95). This suggests that the mean may be slightly inflated by the higher values in the dataset. The median and mode might provide a more accurate representation of the \"typical\" study time for students in this sample, as they are less affected by extreme values.\\n\\nIn particular, the mode (2) indicates that the most common study time among students is 2 hours per day. This information can be valuable in understanding the study habits of the students. However, it is essential to consider all three measures of central tendency (mean, median, and mode) to get a comprehensive understanding of the data.',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.get_example(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5774105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314f818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4be9167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®é›†æ€»é•¿åº¦: 567656\n",
      "\n",
      "è®¿é—®ç¬¬ 0 æ¡æ•°æ®:\n",
      "{'messages': [{'role': 'user', 'content': \"Multiple Choice question: Hadrian's Wall Hadrian's Wall was built, beginning in 122 AD, to keep Roman Britain safe from attacks from the Picts. The wall, starting from the North Sea to the Irish Sea (from the Tyne to the Solway), is about 73 miles long, 10 feet wide, and 15 feet high. In addition to the wall, the Romans built a system of small forts  housing up to 60 men every Roman mile along its whole length, with e towers very 1/3 Roman mile. 16 larger forts holding from 500 to 1000 soldiers were built into the wall, with large gates on the north face. Israeli West Bank barrier The Israeli West Bank barrier is a barrier under construction by the State of Israel along and within the West Bank. Upon completion, the barrier's total length will be nearly 700 kilometers. The barrier is built mainly in the West Bank. The Berlin Wall The Berlin Wall was the physical boundary between West Germany and East Germany. The Berlin Wall was built in the dead of night in 1961 and for 28 years kept East Germans from escaping to the West. Its destruction (in 1989) was celebrated around the world. Conwy's Town Walls Conwy's Town Walls are an ancient defensive   project around the town of Conwy in North Wales. The walls were built between 1283 and 1287. They are 1.3 kilometers long and include 21 towers and three gate houses. The project was completed by large quantities of workers and cost around PS15,000. Today the walls form part of the UNESCO world heritage site . According to the passage, Conwy's Town Walls  _  .\\n- have 21 gatehouses=A\\n- were built in the twelfth century=B\\n- were built for the purpose of defense=C\\n- will soon become a UNSCO world heritage site=D\\n\\nRespond only with the letter of the correct answer.\"}, {'role': 'assistant', 'content': 'C'}], 'subject': '', 'letters': ('A', 'B', 'C', 'D')}\n",
      "\n",
      "è®¿é—®ç¬¬ 100 æ¡æ•°æ®:\n",
      "{'messages': [{'content': 'The sum of the first n natural numbers is given by n*(n+1)/2. Show how this can be derived using a combination of mathematical reasoning and visual insight.', 'role': 'user'}, {'content': \"The formula for the sum of the first n natural numbers can be beautifully derived by combining mathematical reasoning with a dash of visual insight. Let's start by arranging the first n natural numbers in two different ways.\\n\\nImagine listing the numbers 1 to n in an ascending order, and then placing the same numbers in descending order right below them. The resulting pattern would look something like this:\\n\\n1  + 2  + 3  + ... + (n-2) + (n-1) + n\\nn  + (n-1) + (n-2) + ... + 3  + 2  + 1\\n\\nBy adding these two rows together, we notice a fascinating pattern - each pair of numbers adds up to n+1. Since there are n pairs of numbers, the total sum of both rows is n*(n+1).\\n\\nHowever, we've actually added the sum of the first n natural numbers twice, once in each row. To find the sum of just one row, we need to divide this total by 2. Thus, the sum of the first n natural numbers is n*(n+1)/2.\\n\\nThis visual arrangement not only helps us derive the formula but also provides a glimpse into the underlying structure of arithmetic sequences. By recognizing the symmetry and pattern in the arrangement, we can bypass cumbersome calculations and arrive at the formula through elegant reasoning. This approach serves as a testament to the power of combining mathematical logic with creative visualization.\", 'role': 'assistant'}, {'content': 'How does this derivation generalize to the sum of squares of the first n natural numbers? Can the same principle be applied to derive a formula for this case as well?', 'role': 'user'}, {'content': \"The derivation for the sum of squares of the first n natural numbers requires a slightly different approach, yet it still leverages the power of pattern recognition and clever algebraic manipulation. While the simple pairing technique used earlier doesn't directly apply, we can employ a related method to find the formula.\\n\\nOne way to approach this problem is to consider the sum of cubes of the first n natural numbers and then use it to derive the sum of squares. This might seem counterintuitive, but bear with me for a moment.\\n\\nThe key insight comes from the identity:\\n\\nk^3 - (k-1)^3 = 3k^2 - 3k + 1\\n\\nBy summing this identity from k=1 to n, we can telescope the left-hand side:\\n\\n1^3 - 0^3 + 2^3 - 1^3 + 3^3 - 2^3 + ... + n^3 - (n-1)^3 = 3(1^2 + 2^2 + ... + n^2) - 3(1 + 2 + ... + n) + n\\n\\nThe left-hand side simplifies to n^3, and we can use our previously derived formula for the sum of the first n natural numbers to substitute into the right-hand side.\\n\\nn^3 = 3(1^2 + 2^2 + ... + n^2) - 3n(n+1)/2 + n\\n\\nNow, solving for the sum of squares:\\n\\n1^2 + 2^2 + ... + n^2 = (n^3 + 3n(n+1)/2 - n)/3\\n\\nAfter some algebraic manipulation, we arrive at the formula:\\n\\n1^2 + 2^2 + ... + n^2 = n(n+1)(2n+1)/6\\n\\nThis approach, while not directly using the same pairing technique, still relies on clever pattern recognition and algebraic manipulation. By considering the sum of cubes and then using it to derive the sum of squares, we've leveraged the interconnectedness of different mathematical structures to arrive at our desired formula.\\n\\nKeep in mind that there are other ways to derive this formula, and exploring these alternative approaches can provide additional insights into the underlying mathematical relationships.\", 'role': 'assistant'}, {'content': 'How does the formula for the sum of squares relate to the concept of quadratic polynomials, or parabolas in geometry?', 'role': 'user'}, {'content': \"The formula for the sum of squares has an intimate connection with quadratic polynomials, particularly in the context of parabolas. To see this connection, let's consider a parabola defined by the quadratic polynomial f(x) = x^2.\\n\\nImagine approximating the area under this parabola between x=0 and x=n using rectangles. We can divide the area into n rectangles, each with width 1 and height equal to the value of the parabola at the right endpoint of the interval (i.e., f(k) = k^2).\\n\\nThe total area of these rectangles approximates the area under the parabola. Notice that the sum of the areas of these rectangles is precisely the sum of the squares of the first n natural numbers: 1^2 + 2^2 + ... + n^2.\\n\\nNow, using the formula we derived earlier, we can express this sum as n(n+1)(2n+1)/6. This formula provides a closed-form expression for the approximate area under the parabola.\\n\\nIn the limit as n approaches infinity, this approximation becomes exact, and the sum of squares formula yields the area under the parabola. This connection highlights the deep relationship between the sum of squares and the geometry of parabolas.\\n\\nIn fact, this idea can be generalized to other quadratic polynomials. For a parabola defined by f(x) = ax^2 + bx + c, the sum of squares formula can be used to compute the area under the parabola between two points. This connection demonstrates how the formula for the sum of squares is not just a simple arithmetic result but has far-reaching implications in geometry and calculus.\\n\\nMoreover, this connection can be seen as a precursor to the development of more advanced mathematical concepts, such as integration and the Fundamental Theorem of Calculus. The sum of squares formula, derived through arithmetic and algebraic manipulations, finds its true power when applied to the study of geometric shapes and functions, revealing the intricate relationships between different areas of mathematics.\", 'role': 'assistant'}]}\n",
      "\n",
      "è®¿é—®æœ€åä¸€æ¡æ•°æ®:\n",
      "{'messages': [{'content': 'Write a Python function `remove_multiple_whitespace(s)` that takes a string `s` as input, and returns a new string with any consecutive whitespace characters in `s` replaced with a single space character.\\n\\nExample:\\n\\n```python\\nassert remove_multiple_whitespace(\"hello  world\") == \"hello world\"\\nassert remove_multiple_whitespace(\" hello   world  \") == \" hello world \"\\nassert remove_multiple_whitespace(\"hello world\") == \"hello world\"\\n```', 'role': 'user'}, {'content': \"To write a Python function that removes any consecutive whitespace characters in a given string, you can follow these steps:\\n\\n1. Define a function that takes a string as input and returns a new string with any consecutive whitespace characters replaced with a single space character.\\n2. Use the `re` module to replace consecutive whitespace characters with a single space character using a regular expression.\\n3. Return the resulting string.\\n\\nHere's how you can implement this:\\n\\n```python\\nimport re\\n\\ndef remove_multiple_whitespace(s):\\n    return re.sub(r'\\\\s+', ' ', s)\\n```\\n\\nThis implementation uses the `re` module to replace any consecutive whitespace characters with a single space character using a regular expression. The regular expression `\\\\s+` matches one or more consecutive whitespace characters, and the `re.sub()` function replaces them with a single space character.\", 'role': 'assistant'}]}\n",
      "\n",
      "éå†å‰ 5 æ¡æ•°æ®:\n",
      "ç´¢å¼• 0: åŒ…å« 2 æ¡æ¶ˆæ¯\n",
      "ç´¢å¼• 1: åŒ…å« 2 æ¡æ¶ˆæ¯\n",
      "ç´¢å¼• 2: åŒ…å« 2 æ¡æ¶ˆæ¯\n",
      "ç´¢å¼• 3: åŒ…å« 2 æ¡æ¶ˆæ¯\n",
      "ç´¢å¼• 4: åŒ…å« 2 æ¡æ¶ˆæ¯\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from tasks.common import TaskMixture, Task\n",
    "from tasks.smoltalk import SmolTalk\n",
    "from tasks.mmlu import MMLU\n",
    "from tasks.gsm8k import GSM8K\n",
    "\n",
    "# æ–¹å¼1: ä½¿ç”¨ç°æœ‰çš„ Task ç±»åˆ›å»º TaskMixture\n",
    "train_dataset = TaskMixture([\n",
    "    SmolTalk(split=\"train\"),  # 460K æ¡å¯¹è¯\n",
    "    MMLU(subset=\"auxiliary_train\", split=\"train\"),  # 100K æ¡å¤šé€‰é¢˜\n",
    "    GSM8K(subset=\"main\", split=\"train\"),  # 8K æ¡æ•°å­¦é¢˜\n",
    "])\n",
    "\n",
    "# ç›´æ¥é€šè¿‡ç´¢å¼•è®¿é—®æ•°æ®\n",
    "print(f\"æ•°æ®é›†æ€»é•¿åº¦: {len(train_dataset)}\")\n",
    "print(f\"\\nè®¿é—®ç¬¬ 0 æ¡æ•°æ®:\")\n",
    "conversation_0 = train_dataset[0]\n",
    "print(conversation_0)\n",
    "\n",
    "print(f\"\\nè®¿é—®ç¬¬ 100 æ¡æ•°æ®:\")\n",
    "conversation_100 = train_dataset[100]\n",
    "print(conversation_100)\n",
    "\n",
    "print(f\"\\nè®¿é—®æœ€åä¸€æ¡æ•°æ®:\")\n",
    "conversation_last = train_dataset[len(train_dataset) - 1]\n",
    "print(conversation_last)\n",
    "\n",
    "# éå†å‰å‡ æ¡æ•°æ®\n",
    "print(f\"\\néå†å‰ 5 æ¡æ•°æ®:\")\n",
    "for i in range(min(5, len(train_dataset))):\n",
    "    conv = train_dataset[i]\n",
    "    print(f\"ç´¢å¼• {i}: åŒ…å« {len(conv.get('messages', []))} æ¡æ¶ˆæ¯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08326dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': \"Multiple Choice question: Hadrian's Wall Hadrian's Wall was built, beginning in 122 AD, to keep Roman Britain safe from attacks from the Picts. The wall, starting from the North Sea to the Irish Sea (from the Tyne to the Solway), is about 73 miles long, 10 feet wide, and 15 feet high. In addition to the wall, the Romans built a system of small forts  housing up to 60 men every Roman mile along its whole length, with e towers very 1/3 Roman mile. 16 larger forts holding from 500 to 1000 soldiers were built into the wall, with large gates on the north face. Israeli West Bank barrier The Israeli West Bank barrier is a barrier under construction by the State of Israel along and within the West Bank. Upon completion, the barrier's total length will be nearly 700 kilometers. The barrier is built mainly in the West Bank. The Berlin Wall The Berlin Wall was the physical boundary between West Germany and East Germany. The Berlin Wall was built in the dead of night in 1961 and for 28 years kept East Germans from escaping to the West. Its destruction (in 1989) was celebrated around the world. Conwy's Town Walls Conwy's Town Walls are an ancient defensive   project around the town of Conwy in North Wales. The walls were built between 1283 and 1287. They are 1.3 kilometers long and include 21 towers and three gate houses. The project was completed by large quantities of workers and cost around PS15,000. Today the walls form part of the UNESCO world heritage site . According to the passage, Conwy's Town Walls  _  .\\n- have 21 gatehouses=A\\n- were built in the twelfth century=B\\n- were built for the purpose of defense=C\\n- will soon become a UNSCO world heritage site=D\\n\\nRespond only with the letter of the correct answer.\"},\n",
       "  {'role': 'assistant', 'content': 'C'}],\n",
       " 'subject': '',\n",
       " 'letters': ('A', 'B', 'C', 'D')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
