{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8dfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7800ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe82d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93f563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad99ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数量: 13664256\n",
      "\n",
      "输入形状: torch.Size([2, 5])\n",
      "Logits 形状: torch.Size([2, 5, 50304])\n",
      "\n",
      "Training Loss: 10.8258\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "from nanochat.gpt import GPT, GPTConfig\n",
    "\n",
    "# 1. 定义配置 (这里使用一个小模型作为演示)\n",
    "config = GPTConfig(\n",
    "    vocab_size=50304, # 词表大小\n",
    "    sequence_len=1024,# 最大上下文长度\n",
    "    n_layer=4,        # Transformer 层数\n",
    "    n_head=4,         # 注意力头数\n",
    "    n_kv_head=4,   \n",
    "    n_embd=128        # 嵌入维度\n",
    ")\n",
    "\n",
    "# 2. 实例化模型\n",
    "model = GPT(config)\n",
    "\n",
    "# 3. 初始化权重 (关键步骤)\n",
    "# 应用特定的正态分布初始化，并将 lm_head 和部分投影层置零\n",
    "model.init_weights()\n",
    "\n",
    "print(f\"模型参数量: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# --- 场景 A: 推理 (Inference) ---\n",
    "# 构造模拟输入: Batch Size=2, Sequence Length=16\n",
    "B, T = 2, 5\n",
    "idx = torch.randint(0, config.vocab_size, (B, T))\n",
    "\n",
    "# 前向传播 (不传 targets)\n",
    "logits = model(idx)\n",
    "\n",
    "# 输出形状: (Batch, Seq_Len, Vocab_Size)\n",
    "print(f\"\\n输入形状: {idx.shape}\")\n",
    "print(f\"Logits 形状: {logits.shape}\") # -> torch.Size([2, 16, 50304])\n",
    "\n",
    "\n",
    "# --- 场景 B: 训练 (Training) ---\n",
    "# 构造模拟目标 (通常是 idx 向后移一位)\n",
    "targets = torch.randint(0, config.vocab_size, (B, T))\n",
    "\n",
    "# 前向传播 (传入 targets)\n",
    "loss = model(idx, targets=targets)\n",
    "\n",
    "# 输出是一个标量 Loss\n",
    "print(f\"\\nTraining Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747f9430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50225,  8774,  1447,  6861, 46644, 25897, 39148, 21490, 15152, 29623,\n",
       "          1377, 18267, 20870, 17969, 33869, 40159],\n",
       "        [41792, 36984, 17243, 16975, 12120, 11724, 27727, 35220, 29049, 11822,\n",
       "          5502, 20497, 14346, 23403, 19113, 21961]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d906e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token = logits[:, -1, :]\n",
    "print(f\"next_token形状: {next_token.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866401d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81f881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992e58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0296aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TOKENS: 33\n",
      "['W', 'eng', ' earns', ' $', '12', ' an', ' hour', ' for', ' bab', 'ys', 'itting', '.', ' Y', 'ester', 'day', ',', ' she', ' just', ' did', ' ', '50', ' minutes', ' of', ' bab', 'ys', 'itting', '.', ' How', ' much', ' did', ' she', ' earn', '?']\n",
      "FULL_NUM_TOKENS: 92\n",
      "['<|bos|>', '<|user_start|>', 'W', 'eng', ' earns', ' $', '12', ' an', ' hour', ' for', ' bab', 'ys', 'itting', '.', ' Y', 'ester', 'day', ',', ' she', ' just', ' did', ' ', '50', ' minutes', ' of', ' bab', 'ys', 'itting', '.', ' How', ' much', ' did', ' she', ' earn', '?', '<|user_end|>', '<|assistant_start|>', 'W', 'eng', ' earns', ' ', '12', '/', '60', ' =', ' ', '<|python_start|>', '12', '/', '60', '<|python_end|>', '<|output_start|>', '0', '.', '2', '<|output_end|>', ' per', ' minute', '.', ' Working', ' ', '50', ' minutes', ',', ' she', ' earned', ' ', '0', '.', '2', '*', '50', ' =', ' ', '<|python_start|>', '0', '.', '2', '*', '50', '<|python_end|>', '<|output_start|>', '10', '<|output_end|>', '.\\n', '#', '#', '#', '#', ' ', '10', '<|assistant_end|>']\n",
      "[(\"'<|bos|>'\", 65527, 0), (\"'<|user_start|>'\", 65528, 0), (\"'W'\", 87, 0), (\"'eng'\", 1215, 0), (\"' earns'\", 19585, 0), (\"' $'\", 1794, 0), (\"'12'\", 1029, 0), (\"' an'\", 349, 0), (\"' hour'\", 4076, 0), (\"' for'\", 327, 0), (\"' bab'\", 2353, 0), (\"'ys'\", 638, 0), (\"'itting'\", 12884, 0), (\"'.'\", 46, 0), (\"' Y'\", 704, 0), (\"'ester'\", 6995, 0), (\"'day'\", 1126, 0), (\"','\", 44, 0), (\"' she'\", 953, 0), (\"' just'\", 916, 0), (\"' did'\", 1197, 0), (\"' '\", 32, 0), (\"'50'\", 1288, 0), (\"' minutes'\", 2522, 0), (\"' of'\", 282, 0), (\"' bab'\", 2353, 0), (\"'ys'\", 638, 0), (\"'itting'\", 12884, 0), (\"'.'\", 46, 0), (\"' How'\", 1035, 0), (\"' much'\", 1005, 0), (\"' did'\", 1197, 0), (\"' she'\", 953, 0), (\"' earn'\", 6741, 0), (\"'?'\", 63, 0), (\"'<|user_end|>'\", 65529, 0), (\"'<|assistant_start|>'\", 65530, 0), (\"'W'\", 87, 1), (\"'eng'\", 1215, 1), (\"' earns'\", 19585, 1), (\"' '\", 32, 1), (\"'12'\", 1029, 1), (\"'/'\", 47, 1), (\"'60'\", 1924, 1), (\"' ='\", 3146, 1), (\"' '\", 32, 1), (\"'<|python_start|>'\", 65532, 1), (\"'12'\", 1029, 1), (\"'/'\", 47, 1), (\"'60'\", 1924, 1), (\"'<|python_end|>'\", 65533, 1), (\"'<|output_start|>'\", 65534, 0), (\"'0'\", 48, 0), (\"'.'\", 46, 0), (\"'2'\", 50, 0), (\"'<|output_end|>'\", 65535, 0), (\"' per'\", 541, 1), (\"' minute'\", 7085, 1), (\"'.'\", 46, 1), (\"' Working'\", 13454, 1), (\"' '\", 32, 1), (\"'50'\", 1288, 1), (\"' minutes'\", 2522, 1), (\"','\", 44, 1), (\"' she'\", 953, 1), (\"' earned'\", 10703, 1), (\"' '\", 32, 1), (\"'0'\", 48, 1), (\"'.'\", 46, 1), (\"'2'\", 50, 1), (\"'*'\", 42, 1), (\"'50'\", 1288, 1), (\"' ='\", 3146, 1), (\"' '\", 32, 1), (\"'<|python_start|>'\", 65532, 1), (\"'0'\", 48, 1), (\"'.'\", 46, 1), (\"'2'\", 50, 1), (\"'*'\", 42, 1), (\"'50'\", 1288, 1), (\"'<|python_end|>'\", 65533, 1), (\"'<|output_start|>'\", 65534, 0), (\"'10'\", 734, 0), (\"'<|output_end|>'\", 65535, 0), (\"'.\\\\n'\", 307, 1), (\"'#'\", 35, 1), (\"'#'\", 35, 1), (\"'#'\", 35, 1), (\"'#'\", 35, 1), (\"' '\", 32, 1), (\"'10'\", 734, 1), (\"'<|assistant_end|>'\", 65531, 1)]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from nanochat.tokenizer import get_tokenizer\n",
    "\n",
    "text = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\"\n",
    "\n",
    "tok = get_tokenizer()\n",
    "\n",
    "# 1) 仅对这段 user 文本做 tokenize\n",
    "ids = tok.encode(text)  # list[int]\n",
    "tokens = [tok.id_to_token(i) for i in ids]  # list[str], 每个元素就是一个 token 的“字符串形态”\n",
    "print(\"NUM_TOKENS:\", len(tokens))\n",
    "print(tokens)  # 如果太长你也可以逐行 print\n",
    "\n",
    "# 2) 你的整条 GSM8K conversation 的“完整 token 流”\n",
    "conv = {\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "    {\"role\": \"assistant\", \"content\": [\n",
    "      {\"type\": \"text\", \"text\": \"Weng earns 12/60 = \"},\n",
    "      {\"type\": \"python\", \"text\": \"12/60\"},\n",
    "      {\"type\": \"python_output\", \"text\": \"0.2\"},\n",
    "      {\"type\": \"text\", \"text\": \" per minute. Working 50 minutes, she earned 0.2*50 = \"},\n",
    "      {\"type\": \"python\", \"text\": \"0.2*50\"},\n",
    "      {\"type\": \"python_output\", \"text\": \"10\"},\n",
    "      {\"type\": \"text\", \"text\": \".\\n#### 10\"},\n",
    "    ]},\n",
    "  ]\n",
    "}\n",
    "\n",
    "full_ids, mask = tok.render_conversation(conv)\n",
    "full_tokens = [tok.id_to_token(i) for i in full_ids]\n",
    "print(\"FULL_NUM_TOKENS:\", len(full_tokens))\n",
    "print(full_tokens)\n",
    "\n",
    "# 可选：同时打印 (token, id, mask) 方便核对哪些 token 来自 user/assistant/tool output\n",
    "triples = [(repr(t), i, m) for t, i, m in zip(full_tokens, full_ids, mask)]\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc78c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
