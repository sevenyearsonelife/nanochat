# NanoChat 核心模块文档

本文档详细介绍 `nanochat/` 目录下各个文件的功能和作用。

## 核心文件概览

| 文件名 | 功能描述 | 主要用途 |
|--------|----------|----------|
| **gpt.py** | Transformer 模型核心实现 | 大语言模型架构定义 |
| **tokenizer.py** | BPE 分词器实现 | 文本与 token 之间的转换 |
| **engine.py** | 高效推理引擎 | 模型推理和生成 |
| **dataloader.py** | 分布式数据加载器 | 训练数据流处理 |
| **common.py** | 通用工具函数 | 日志、分布式、文件操作等 |
| **configurator.py** | 配置管理器 | 命令行参数和配置文件处理 |
| **checkpoint_manager.py** | 模型检查点管理 | 模型保存和加载 |
| **adamw.py** | 分布式 AdamW 优化器 | 嵌入层参数优化 |
| **muon.py** | 分布式 Muon 优化器 | 矩阵参数优化 |
| **dataset.py** | 数据集管理 | 预训练数据下载和处理 |
| **core_eval.py** | CORE 评估指标 | 模型性能评估 |
| **loss_eval.py** | 损失评估工具 | 基础模型损失计算 |
| **execution.py** | 代码执行沙箱 | 安全的 Python 代码执行 |
| **report.py** | 训练报告生成器 | 生成训练统计报告 |
| **ui.html** | Web 界面 | 聊天界面前端 |
| **logo.svg** | 项目图标 | 品牌标识 |
| **__init__.py** | 包初始化文件 | Python 包定义 |

## 详细功能说明

### 🧠 核心模型组件

#### `gpt.py` - Transformer 模型实现
**功能**: 实现 GPT 风格的 Transformer 架构

**主要特性**:
- **Rotary Embeddings**: 使用旋转位置编码替代传统位置编码
- **QK Norm**: 在注意力机制中对查询和键进行归一化
- **解绑权重**: token embedding 和 lm_head 使用独立权重
- **ReLU² 激活**: MLP 层使用平方 ReLU 激活函数
- **无偏置设计**: 线性层不包含 bias 参数
- **MQA 支持**: 多查询注意力机制，提高推理效率

**关键类**:
- `GPTConfig`: 模型配置类，定义模型超参数
- `GPT`: 主模型类，包含完整的 Transformer 架构

#### `tokenizer.py` - BPE 分词器
**功能**: 实现 GPT-4 风格的 BPE (Byte Pair Encoding) 分词器

**实现方式**:
1. **HuggingFace Tokenizer**: 完整功能但使用复杂
2. **RustBPE + tiktoken**: 高性能组合，Rust 训练 + tiktoken 推理

**特殊标记**:
```
<|bos|>: 序列开始标记
<|user_start|>/<|user_end|>: 用户消息标记
<|assistant_start|>/<|assistant_end|>: 助手消息标记
<|python_start|>/<|python_end|>: Python 代码标记
<|output_start|>/<|output_end|>: 输出标记
```

#### `engine.py` - 推理引擎
**功能**: 高效的模型推理引擎，专注于 token 序列处理

**核心特性**:
- **纯 token 操作**: 引擎只处理 token ID，不关心分词
- **高效推理**: 针对生成任务优化的推理流程
- **计算器工具**: 内置安全的 Python 表达式求值
- **超时保护**: 防止代码执行时间过长

**关键函数**:
- `use_calculator()`: 安全的数学表达式计算
- `eval_with_timeout()`: 带超时的表达式求值

### 🔄 训练基础设施

#### `dataloader.py` - 分布式数据加载器
**功能**: 高效的分布式训练数据流处理

**核心流程**:
1. 从 Parquet 文件流式读取文档
2. 多线程分词处理
3. 构造训练批次 (inputs/targets)
4. GPU 内存固定优化

**关键特性**:
- **流式处理**: 避免内存溢出的大数据集处理
- **分布式支持**: 自动处理 DDP (分布式数据并行)
- **内存优化**: 使用 CUDA pinned memory 加速传输
- **动态批处理**: 智能批次大小调整

#### `adamw.py` - 分布式 AdamW 优化器
**功能**: ZeRO-2 风格的分布式 AdamW 优化器

**主要用途**: 嵌入层参数优化

**核心特性**:
- **分片状态**: 优化器状态在多 GPU 间分片存储
- **梯度规约**: 分布式梯度聚合和平均
- **内存优化**: 显著减少单 GPU 内存占用

#### `muon.py` - 分布式 Muon 优化器
**功能**: 矩阵参数专用优化器，基于牛顿-舒尔茨迭代

**算法原理**:
- **正交化更新**: 将 SGD 更新投影到最近的正交矩阵
- **牛顿-舒尔茨**: 高效的矩阵正交化算法
- **bfloat16 优化**: 在保持精度的同时提高计算效率

**适用范围**: 主要用于 Transformer 的线性层参数

### 🛠️ 工具和辅助模块

#### `common.py` - 通用工具函数
**功能**: 项目通用工具和实用函数集合

**主要组件**:
- **彩色日志**: 带颜色格式化的日志输出
- **分布式信息**: DDP 环境信息获取
- **文件路径**: 基础目录管理和路径处理
- **网络下载**: 文件下载工具函数

**关键类**:
- `ColoredFormatter`: 自定义彩色日志格式器

#### `configurator.py` - 配置管理器
**功能**: 轻量级配置管理，替代复杂的配置系统

**使用方式**:
```python
# 从配置文件加载
python train.py config/override_file.py

# 命令行参数覆盖
python train.py --batch_size=32 --learning_rate=1e-4
```

**设计理念**:
- 零配置文件前缀
- 直接全局变量覆盖
- 自动类型转换和验证

#### `checkpoint_manager.py` - 检查点管理
**功能**: 模型和优化器状态的保存与加载

**保存内容**:
- **模型参数**: `.pt` 格式的模型权重
- **优化器状态**: 用于恢复训练的优化器信息
- **元数据**: JSON 格式的训练配置和统计信息

**关键函数**:
- `save_checkpoint()`: 保存完整的训练状态
- `load_checkpoint()`: 加载指定步数的检查点

### 📊 数据和评估

#### `dataset.py` - 数据集管理
**功能**: 预训练数据集的下载和管理

**数据来源**: HuggingFace `karpathy/fineweb-edu-100b-shuffle` 数据集

**主要功能**:
- **自动下载**: 按需下载 Parquet 数据分片
- **分片管理**: 支持 1822 个数据分片的索引和管理
- **迭代接口**: 提供高效的数据批次迭代器
- **分布式支持**: 自动处理多进程数据分配

#### `core_eval.py` - CORE 评估指标
**功能**: 实现 DCLM 论文中的 CORE 评估指标

**评估任务类型**:
- **多选题**: 标准的选择题评估
- **模式题**: 需要理解结构的题目
- **代码题**: 编程相关任务评估

**关键技术**:
- **Jinja2 模板**: 动态生成评估提示
- **Few-shot 支持**: 支持少样本学习评估
- **分布式评估**: 多 GPU 并行评估

#### `loss_eval.py` - 损失评估
**功能**: 基础模型的损失评估，计算 bits-per-byte (BPB) 指标

**BPB 优势**:
- **词汇表无关**: 不受词汇表大小影响
- **标准化比较**: 不同配置模型间的公平比较
- **特殊标记处理**: 自动排除特殊标记的计算

#### `execution.py` - 代码执行沙箱
**功能**: 安全的 Python 代码执行环境

**安全特性**:
- **进程隔离**: 每次执行在独立进程中运行
- **超时保护**: 防止无限循环和长时间运行
- **内存限制**: 默认 256MB 内存限制
- **危险函数禁用**: 禁用 `os.system`, `subprocess` 等危险函数

**局限性**:
- 非真正安全沙箱 (无内核级隔离)
- 网络访问未完全阻止
- 不能防护恶意对抗代码

### 📈 报告和界面

#### `report.py` - 训练报告生成器
**功能**: 生成详细的训练统计报告

**收集信息**:
- **Git 信息**: 提交哈希、分支、状态
- **硬件信息**: GPU 型号、数量、内存
- **系统信息**: 操作系统、Python 版本
- **训练日志**: 损失曲线、学习率调度

#### `ui.html` - Web 用户界面
**功能**: 现代化的聊天界面前端

**界面特性**:
- **响应式设计**: 适配桌面和移动设备
- **实时对话**: WebSocket 实时通信
- **历史记录**: 对话历史保存和管理
- **暗色模式**: 支持明暗主题切换

#### `logo.svg` - 项目图标
**功能**: NanoChat 项目的品牌标识图标

## 🏗️ 架构设计理念

### 模块化设计
- **单一职责**: 每个模块专注于特定功能
- **松耦合**: 模块间依赖最小化
- **高内聚**: 相关功能集中在同一模块

### 性能优化
- **分布式支持**: 所有核心组件支持多 GPU 并行
- **内存效率**: 流式处理和内存固定优化
- **计算优化**: 使用最新的 PyTorch 编译优化

### 可扩展性
- **插件化架构**: 易于添加新的评估任务和数据集
- **配置驱动**: 通过配置文件控制行为
- **标准接口**: 统一的数据加载和模型接口

## 📝 开发建议

### 添加新功能
1. **新评估任务**: 在 `tasks/` 目录下添加新任务
2. **新优化器**: 参考 `adamw.py` 和 `muon.py` 的模式
3. **新数据集**: 扩展 `dataset.py` 支持新格式

### 性能调优
1. **批次大小**: 通过 `device_batch_size` 调整
2. **梯度累积**: 自动调整以保持总批次大小
3. **混合精度**: 在训练脚本中启用

### 调试技巧
1. **日志级别**: 通过环境变量控制日志详细程度
2. **梯度检查**: 使用 `torch.autograd.detect_anomaly()`
3. **内存分析**: 使用 `torch.cuda.memory_summary()`

---

这份文档提供了 NanoChat 项目 `nanochat/` 目录的全面概览。每个文件都经过精心设计，共同构建了一个高效、可扩展的大语言模型训练和推理系统。